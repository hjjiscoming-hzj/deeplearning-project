2025-01-10 16:05:09,379 INFO: namespace(attn_dropout=0.4, categories=[], cluster=3, depth=1, dim=16, ff_dropout=0.4, groups=[54, 54, 54], heads=4, name='AMFormer_KAN_dim16_depth1_heads4_dropout0.4', num_cate=0, num_cont=15, num_special_tokens=1, out=1, out_dim=1, predictor='KAN', prod_num_per_group=[6, 6, 6], qk_relu=False, sum_num_per_group=[32, 16, 8], target_mode='regression', token_descent=False, use_cls_token=True, use_prod=True, use_sigmoid=True) 
2025-01-10 16:05:09,379 INFO: Dataset:Bike 
2025-01-10 16:05:09,380 INFO: ------Begin Training Model------ 
2025-01-10 16:05:14,019 INFO: Epoch 1, Train Loss: 0.949735735534528, Test Loss: 0.8300731416259494, Inverse Test Loss: 5.209254673549107 
2025-01-10 16:05:15,220 INFO: Epoch 2, Train Loss: 0.8305353773843258, Test Loss: 0.7818486477647509, Inverse Test Loss: 4.8279893057686945 
2025-01-10 16:05:16,418 INFO: Epoch 3, Train Loss: 0.8148702038537472, Test Loss: 0.7792083663599831, Inverse Test Loss: 4.68413325718471 
2025-01-10 16:05:17,656 INFO: Epoch 4, Train Loss: 0.8094130754470825, Test Loss: 0.7769874121461596, Inverse Test Loss: 5.006023406982422 
2025-01-10 16:05:18,873 INFO: Epoch 5, Train Loss: 0.8066612143035329, Test Loss: 0.7764780670404434, Inverse Test Loss: 4.937040601457868 
2025-01-10 16:05:20,096 INFO: Epoch 6, Train Loss: 0.8046027613342355, Test Loss: 0.7739319247858865, Inverse Test Loss: 4.711140223911831 
2025-01-10 16:05:21,321 INFO: Epoch 7, Train Loss: 0.8018781898218558, Test Loss: 0.7731299144881112, Inverse Test Loss: 4.909482683454241 
2025-01-10 16:05:22,528 INFO: Epoch 8, Train Loss: 0.8002443865898552, Test Loss: 0.771141780274255, Inverse Test Loss: 4.766187395368304 
2025-01-10 16:05:23,721 INFO: Epoch 9, Train Loss: 0.797158039491111, Test Loss: 0.7695547704185758, Inverse Test Loss: 4.910909380231585 
2025-01-10 16:05:24,910 INFO: Epoch 10, Train Loss: 0.7948385307548242, Test Loss: 0.7682026645966938, Inverse Test Loss: 4.792333330426898 
2025-01-10 16:05:26,096 INFO: Epoch 11, Train Loss: 0.7931337498743599, Test Loss: 0.7676742949656078, Inverse Test Loss: 4.694353921072824 
2025-01-10 16:05:27,338 INFO: Epoch 12, Train Loss: 0.7914534287715177, Test Loss: 0.7709658571652004, Inverse Test Loss: 5.042037418910435 
2025-01-10 16:05:28,757 INFO: Epoch 13, Train Loss: 0.7906144556649234, Test Loss: 0.7639162093400955, Inverse Test Loss: 4.642331259591239 
2025-01-10 16:05:30,042 INFO: Epoch 14, Train Loss: 0.7933389954610702, Test Loss: 0.7631556966475078, Inverse Test Loss: 4.65515627179827 
2025-01-10 16:05:31,466 INFO: Epoch 15, Train Loss: 0.7897897630656531, Test Loss: 0.762926887188639, Inverse Test Loss: 4.521066393171038 
2025-01-10 16:05:32,904 INFO: Epoch 16, Train Loss: 0.7892562457180898, Test Loss: 0.7647455313376018, Inverse Test Loss: 4.7602032252720425 
2025-01-10 16:05:34,578 INFO: Epoch 17, Train Loss: 0.7886142840079211, Test Loss: 0.7639678354774203, Inverse Test Loss: 4.384011132376535 
2025-01-10 16:05:36,103 INFO: Epoch 18, Train Loss: 0.7858701506885913, Test Loss: 0.7586534257446017, Inverse Test Loss: 4.4839308602469305 
2025-01-10 16:05:37,803 INFO: Epoch 19, Train Loss: 0.7839440993212778, Test Loss: 0.7631143267665591, Inverse Test Loss: 4.7048138209751675 
2025-01-10 16:05:39,369 INFO: Epoch 20, Train Loss: 0.7834508298733912, Test Loss: 0.7563910356589726, Inverse Test Loss: 4.429258074079241 
2025-01-10 16:05:40,900 INFO: Epoch 21, Train Loss: 0.7837799891419367, Test Loss: 0.7537722545010703, Inverse Test Loss: 4.158876964024135 
2025-01-10 16:05:42,375 INFO: Epoch 22, Train Loss: 0.7814089983975122, Test Loss: 0.7537698979888644, Inverse Test Loss: 4.285908290318081 
2025-01-10 16:05:44,100 INFO: Epoch 23, Train Loss: 0.7817252349416051, Test Loss: 0.7509006772722516, Inverse Test Loss: 3.9837423052106584 
2025-01-10 16:05:45,593 INFO: Epoch 24, Train Loss: 0.780633334172975, Test Loss: 0.7575044993843351, Inverse Test Loss: 4.442189080374582 
2025-01-10 16:05:47,130 INFO: Epoch 25, Train Loss: 0.7797782650781334, Test Loss: 0.7512549757957458, Inverse Test Loss: 4.1222430637904575 
2025-01-10 16:05:48,727 INFO: Epoch 26, Train Loss: 0.7781893277387006, Test Loss: 0.7475766007389341, Inverse Test Loss: 4.063968658447266 
2025-01-10 16:05:50,159 INFO: Epoch 27, Train Loss: 0.7778095466281296, Test Loss: 0.7487638337271554, Inverse Test Loss: 4.116428102765765 
2025-01-10 16:05:51,540 INFO: Epoch 28, Train Loss: 0.7760322154115099, Test Loss: 0.7470404484442302, Inverse Test Loss: 4.042582103184292 
2025-01-10 16:05:53,116 INFO: Epoch 29, Train Loss: 0.7768699444762064, Test Loss: 0.7474392609936851, Inverse Test Loss: 3.9783834729875838 
2025-01-10 16:05:54,579 INFO: Epoch 30, Train Loss: 0.7770672145239804, Test Loss: 0.7456163593700954, Inverse Test Loss: 4.056004387991769 
2025-01-10 16:05:56,138 INFO: Epoch 31, Train Loss: 0.7733579518598154, Test Loss: 0.7461235033614295, Inverse Test Loss: 4.170626776559012 
2025-01-10 16:05:57,703 INFO: Epoch 32, Train Loss: 0.7769437454162388, Test Loss: 0.7460259795188904, Inverse Test Loss: 3.855487823486328 
2025-01-10 16:05:58,997 INFO: Epoch 33, Train Loss: 0.770026421875035, Test Loss: 0.743654306445803, Inverse Test Loss: 3.862431389944894 
2025-01-10 16:06:00,217 INFO: Epoch 34, Train Loss: 0.7722789568638583, Test Loss: 0.7414798608848027, Inverse Test Loss: 3.7756380353655135 
2025-01-10 16:06:01,436 INFO: Epoch 35, Train Loss: 0.770113655733406, Test Loss: 0.7444083243608475, Inverse Test Loss: 3.7558901650565013 
2025-01-10 16:06:02,716 INFO: Epoch 36, Train Loss: 0.7730266626821746, Test Loss: 0.7396428138017654, Inverse Test Loss: 3.807969229561942 
2025-01-10 16:06:04,116 INFO: Epoch 37, Train Loss: 0.7718928746127207, Test Loss: 0.740160637668201, Inverse Test Loss: 3.909579413277762 
2025-01-10 16:06:05,395 INFO: Epoch 38, Train Loss: 0.7688921744670343, Test Loss: 0.739996959056173, Inverse Test Loss: 3.87441771371024 
2025-01-10 16:06:06,798 INFO: Epoch 39, Train Loss: 0.7697182483629349, Test Loss: 0.7412545489413398, Inverse Test Loss: 3.7905951908656528 
2025-01-10 16:06:08,184 INFO: Epoch 40, Train Loss: 0.7706039892424137, Test Loss: 0.7389496117830276, Inverse Test Loss: 3.781524658203125 
2025-01-10 16:06:09,742 INFO: Epoch 41, Train Loss: 0.7698868835737945, Test Loss: 0.7381754900727954, Inverse Test Loss: 3.9343659537179128 
2025-01-10 16:06:11,131 INFO: Epoch 42, Train Loss: 0.7669664736187786, Test Loss: 0.7384528794458934, Inverse Test Loss: 3.841068812779018 
2025-01-10 16:06:12,579 INFO: Epoch 43, Train Loss: 0.7669036940697136, Test Loss: 0.7390945340905871, Inverse Test Loss: 3.7231927599225725 
2025-01-10 16:06:13,868 INFO: Epoch 44, Train Loss: 0.7657118127980364, Test Loss: 0.7378693052700588, Inverse Test Loss: 3.770627975463867 
2025-01-10 16:06:15,159 INFO: Epoch 45, Train Loss: 0.7683574519026171, Test Loss: 0.7367565355130604, Inverse Test Loss: 3.943171909877232 
2025-01-10 16:06:16,744 INFO: Epoch 46, Train Loss: 0.7654980940556307, Test Loss: 0.7381578300680433, Inverse Test Loss: 4.082368578229632 
2025-01-10 16:06:18,472 INFO: Epoch 47, Train Loss: 0.7658390222339455, Test Loss: 0.7351707198790142, Inverse Test Loss: 3.9203480311802457 
2025-01-10 16:06:20,166 INFO: Epoch 48, Train Loss: 0.7624159903701292, Test Loss: 0.7372947675841195, Inverse Test Loss: 3.7609795161655972 
2025-01-10 16:06:21,753 INFO: Epoch 49, Train Loss: 0.7653432493909783, Test Loss: 0.7336075135639736, Inverse Test Loss: 3.784834453037807 
2025-01-10 16:06:23,144 INFO: Epoch 50, Train Loss: 0.76191798645422, Test Loss: 0.7345385466303144, Inverse Test Loss: 3.8034801483154297 
2025-01-10 16:06:24,344 INFO: Epoch 51, Train Loss: 0.7678187965253077, Test Loss: 0.7395329581839698, Inverse Test Loss: 4.200547082083566 
2025-01-10 16:06:25,555 INFO: Epoch 52, Train Loss: 0.7644556984988922, Test Loss: 0.7356429419347218, Inverse Test Loss: 3.9056876046316966 
2025-01-10 16:06:26,756 INFO: Epoch 53, Train Loss: 0.7651412820597308, Test Loss: 0.7355050700051444, Inverse Test Loss: 3.8706558772495816 
