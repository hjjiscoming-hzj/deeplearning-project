2025-01-10 14:58:42,136 INFO: namespace(attn_dropout=0.4, categories=[], cluster=3, depth=1, dim=16, ff_dropout=0.4, groups=[54, 54, 54], heads=4, name='AMFormer_KAN_dim16_depth1_heads4_dropout0.4', num_cate=0, num_cont=15, num_special_tokens=1, out=1, out_dim=1, predictor='KAN', prod_num_per_group=[6, 6, 6], qk_relu=False, sum_num_per_group=[32, 16, 8], target_mode='regression', token_descent=False, use_cls_token=True, use_prod=True, use_sigmoid=True) 
2025-01-10 14:58:42,137 INFO: Dataset:Bike 
2025-01-10 14:58:42,137 INFO: ------Begin Training Model------ 
2025-01-10 14:58:46,806 INFO: Epoch 1, Train Loss: 0.9174800930766884, Test Loss: 0.8003126191241401, Inverse Test Loss: 4.430584226335798 
2025-01-10 14:58:48,064 INFO: Epoch 2, Train Loss: 0.823631832359034, Test Loss: 0.7862942282642637, Inverse Test Loss: 4.87390627179827 
2025-01-10 14:58:49,320 INFO: Epoch 3, Train Loss: 0.8140250695954769, Test Loss: 0.7778862714767456, Inverse Test Loss: 4.756493159702846 
2025-01-10 14:58:50,541 INFO: Epoch 4, Train Loss: 0.8085602538301311, Test Loss: 0.7800397617476327, Inverse Test Loss: 4.973897661481585 
2025-01-10 14:58:51,759 INFO: Epoch 5, Train Loss: 0.8048509780420076, Test Loss: 0.7738278976508549, Inverse Test Loss: 4.635459899902344 
2025-01-10 14:58:53,037 INFO: Epoch 6, Train Loss: 0.8027104751779399, Test Loss: 0.7739314926522118, Inverse Test Loss: 4.771519797188895 
2025-01-10 14:58:54,267 INFO: Epoch 7, Train Loss: 0.7996361572808082, Test Loss: 0.7742247730493546, Inverse Test Loss: 4.796447208949497 
2025-01-10 14:58:55,600 INFO: Epoch 8, Train Loss: 0.7968927517943426, Test Loss: 0.7711062942232404, Inverse Test Loss: 4.581676483154297 
2025-01-10 14:58:56,880 INFO: Epoch 9, Train Loss: 0.795931428944299, Test Loss: 0.7701711973973683, Inverse Test Loss: 4.726724352155413 
2025-01-10 14:58:58,372 INFO: Epoch 10, Train Loss: 0.7941455600458548, Test Loss: 0.7730207123926708, Inverse Test Loss: 4.904058728899274 
2025-01-10 14:58:59,815 INFO: Epoch 11, Train Loss: 0.795183536656406, Test Loss: 0.768392760838781, Inverse Test Loss: 4.588043212890625 
2025-01-10 14:59:01,351 INFO: Epoch 12, Train Loss: 0.7950624216587172, Test Loss: 0.7697444813592094, Inverse Test Loss: 4.36422484261649 
2025-01-10 14:59:02,708 INFO: Epoch 13, Train Loss: 0.7929107891310245, Test Loss: 0.7678822534424918, Inverse Test Loss: 4.52518926348005 
2025-01-10 14:59:04,155 INFO: Epoch 14, Train Loss: 0.7920863650260715, Test Loss: 0.7665344966309411, Inverse Test Loss: 4.338391440255301 
2025-01-10 14:59:05,693 INFO: Epoch 15, Train Loss: 0.7901042672472263, Test Loss: 0.7666549107858113, Inverse Test Loss: 4.5008953639439175 
2025-01-10 14:59:07,240 INFO: Epoch 16, Train Loss: 0.7902218119813762, Test Loss: 0.7645055460078376, Inverse Test Loss: 4.409437724522182 
2025-01-10 14:59:08,859 INFO: Epoch 17, Train Loss: 0.7905834071133115, Test Loss: 0.766635326402528, Inverse Test Loss: 4.181652341570173 
2025-01-10 14:59:10,421 INFO: Epoch 18, Train Loss: 0.7882656684709252, Test Loss: 0.7643390021153859, Inverse Test Loss: 4.2582822527204245 
2025-01-10 14:59:11,995 INFO: Epoch 19, Train Loss: 0.7867234070366675, Test Loss: 0.7636003621986934, Inverse Test Loss: 4.20732661655971 
2025-01-10 14:59:13,507 INFO: Epoch 20, Train Loss: 0.7862770404290715, Test Loss: 0.7621068486145565, Inverse Test Loss: 4.4293221064976285 
2025-01-10 14:59:15,045 INFO: Epoch 21, Train Loss: 0.7848434699784725, Test Loss: 0.7610952854156494, Inverse Test Loss: 4.257446834019253 
2025-01-10 14:59:16,614 INFO: Epoch 22, Train Loss: 0.7842293797282998, Test Loss: 0.7587579318455288, Inverse Test Loss: 4.227312088012695 
2025-01-10 14:59:17,919 INFO: Epoch 23, Train Loss: 0.7830170792177182, Test Loss: 0.7580635654074805, Inverse Test Loss: 4.227314267839704 
2025-01-10 14:59:19,423 INFO: Epoch 24, Train Loss: 0.7830838287642242, Test Loss: 0.7566394167287009, Inverse Test Loss: 4.112466812133789 
2025-01-10 14:59:21,211 INFO: Epoch 25, Train Loss: 0.7831570456881042, Test Loss: 0.7603449736322675, Inverse Test Loss: 4.345991134643555 
2025-01-10 14:59:22,691 INFO: Epoch 26, Train Loss: 0.7821556149272744, Test Loss: 0.7554095962217876, Inverse Test Loss: 4.166987555367606 
2025-01-10 14:59:24,304 INFO: Epoch 27, Train Loss: 0.7814188413663742, Test Loss: 0.7550150879791805, Inverse Test Loss: 4.243871416364398 
2025-01-10 14:59:25,844 INFO: Epoch 28, Train Loss: 0.781328244493642, Test Loss: 0.7571534514427185, Inverse Test Loss: 4.115632465907505 
2025-01-10 14:59:27,501 INFO: Epoch 29, Train Loss: 0.7801941556668063, Test Loss: 0.7545482473714011, Inverse Test Loss: 4.089466912405832 
2025-01-10 14:59:29,249 INFO: Epoch 30, Train Loss: 0.7791464295955973, Test Loss: 0.7585080074412482, Inverse Test Loss: 4.43279184613909 
2025-01-10 14:59:30,946 INFO: Epoch 31, Train Loss: 0.780019762865994, Test Loss: 0.7546371902738299, Inverse Test Loss: 4.082913534981864 
2025-01-10 14:59:32,789 INFO: Epoch 32, Train Loss: 0.7809042875919867, Test Loss: 0.7529290169477463, Inverse Test Loss: 4.185783113752093 
2025-01-10 14:59:34,446 INFO: Epoch 33, Train Loss: 0.779931096308822, Test Loss: 0.7530403648103986, Inverse Test Loss: 4.255066190447126 
