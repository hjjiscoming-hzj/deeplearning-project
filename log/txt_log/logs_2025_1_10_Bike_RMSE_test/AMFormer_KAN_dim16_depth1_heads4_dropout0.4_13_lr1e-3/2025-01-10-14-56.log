2025-01-10 14:56:57,659 INFO: namespace(attn_dropout=0.4, categories=[], cluster=3, depth=1, dim=16, ff_dropout=0.4, groups=[54, 54, 54], heads=4, name='AMFormer_KAN_dim16_depth1_heads4_dropout0.4', num_cate=0, num_cont=15, num_special_tokens=1, out=1, out_dim=1, predictor='KAN', prod_num_per_group=[6, 6, 6], qk_relu=False, sum_num_per_group=[32, 16, 8], target_mode='regression', token_descent=False, use_cls_token=True, use_prod=True, use_sigmoid=True) 
2025-01-10 14:56:57,659 INFO: Dataset:Bike 
2025-01-10 14:56:57,659 INFO: ------Begin Training Model------ 
2025-01-10 14:57:02,408 INFO: Epoch 1, Train Loss: 0.9271250760883366, Test Loss: 0.795232817530632, Inverse Test Loss: 4.619824545724051 
2025-01-10 14:57:03,657 INFO: Epoch 2, Train Loss: 0.8189639892053167, Test Loss: 0.784193971327373, Inverse Test Loss: 4.624737875802176 
2025-01-10 14:57:04,880 INFO: Epoch 3, Train Loss: 0.8162207827655548, Test Loss: 0.7848645427397319, Inverse Test Loss: 5.007367270333426 
2025-01-10 14:57:06,101 INFO: Epoch 4, Train Loss: 0.8086460637390067, Test Loss: 0.7774138876370021, Inverse Test Loss: 4.905893053327288 
2025-01-10 14:57:07,310 INFO: Epoch 5, Train Loss: 0.8058955658466445, Test Loss: 0.7773411422967911, Inverse Test Loss: 4.873930249895368 
2025-01-10 14:57:08,511 INFO: Epoch 6, Train Loss: 0.801629647202448, Test Loss: 0.7742767440421241, Inverse Test Loss: 4.656465802873884 
2025-01-10 14:57:09,717 INFO: Epoch 7, Train Loss: 0.7984754109601362, Test Loss: 0.7735168082373483, Inverse Test Loss: 4.860203334263393 
2025-01-10 14:57:10,913 INFO: Epoch 8, Train Loss: 0.7975925032151948, Test Loss: 0.7715814986399242, Inverse Test Loss: 4.6345721653529575 
2025-01-10 14:57:12,112 INFO: Epoch 9, Train Loss: 0.7979124740723076, Test Loss: 0.7719312757253647, Inverse Test Loss: 4.850048065185547 
2025-01-10 14:57:13,324 INFO: Epoch 10, Train Loss: 0.7949467788048841, Test Loss: 0.7701011172362736, Inverse Test Loss: 4.53858757019043 
2025-01-10 14:57:14,548 INFO: Epoch 11, Train Loss: 0.7930833812153667, Test Loss: 0.7720161357096263, Inverse Test Loss: 4.730533054896763 
2025-01-10 14:57:15,767 INFO: Epoch 12, Train Loss: 0.7929443711534553, Test Loss: 0.7721281860555921, Inverse Test Loss: 4.400049754551479 
2025-01-10 14:57:16,991 INFO: Epoch 13, Train Loss: 0.7923040750923507, Test Loss: 0.768611512013844, Inverse Test Loss: 4.542153222220285 
2025-01-10 14:57:18,207 INFO: Epoch 14, Train Loss: 0.7931526407189325, Test Loss: 0.7693757797990527, Inverse Test Loss: 4.403414590018136 
2025-01-10 14:57:19,417 INFO: Epoch 15, Train Loss: 0.7926493095695426, Test Loss: 0.7662598064967564, Inverse Test Loss: 4.505405153547015 
2025-01-10 14:57:20,618 INFO: Epoch 16, Train Loss: 0.7892993196434931, Test Loss: 0.7669044945921216, Inverse Test Loss: 4.638205936976841 
2025-01-10 14:57:21,847 INFO: Epoch 17, Train Loss: 0.7893067089789504, Test Loss: 0.7675905483109611, Inverse Test Loss: 4.4630938938685825 
2025-01-10 14:57:23,073 INFO: Epoch 18, Train Loss: 0.7857689742648274, Test Loss: 0.7668258760656629, Inverse Test Loss: 4.571571895054409 
2025-01-10 14:57:24,284 INFO: Epoch 19, Train Loss: 0.7876830855640796, Test Loss: 0.7683837137051991, Inverse Test Loss: 4.610929761614118 
2025-01-10 14:57:25,495 INFO: Epoch 20, Train Loss: 0.7882313875977053, Test Loss: 0.7639601592506681, Inverse Test Loss: 4.428816386631557 
2025-01-10 14:57:26,696 INFO: Epoch 21, Train Loss: 0.7867540924920948, Test Loss: 0.7643354002918515, Inverse Test Loss: 4.228328159877232 
2025-01-10 14:57:27,896 INFO: Epoch 22, Train Loss: 0.7860752256638414, Test Loss: 0.7634755522012711, Inverse Test Loss: 4.334222793579102 
2025-01-10 14:57:29,115 INFO: Epoch 23, Train Loss: 0.783250952532532, Test Loss: 0.7614393766437259, Inverse Test Loss: 4.2720827375139505 
2025-01-10 14:57:30,321 INFO: Epoch 24, Train Loss: 0.7840697470061276, Test Loss: 0.7614583373069763, Inverse Test Loss: 4.388246536254883 
2025-01-10 14:57:31,535 INFO: Epoch 25, Train Loss: 0.7871677574761416, Test Loss: 0.7611153955970492, Inverse Test Loss: 4.429305212838309 
2025-01-10 14:57:32,733 INFO: Epoch 26, Train Loss: 0.7851892277735089, Test Loss: 0.7609732768365315, Inverse Test Loss: 4.226116452898298 
2025-01-10 14:57:33,948 INFO: Epoch 27, Train Loss: 0.780460951525137, Test Loss: 0.7601602460656848, Inverse Test Loss: 4.052804674421038 
2025-01-10 14:57:35,177 INFO: Epoch 28, Train Loss: 0.7851575356010997, Test Loss: 0.7579945347138813, Inverse Test Loss: 4.227390289306641 
2025-01-10 14:57:36,380 INFO: Epoch 29, Train Loss: 0.7809273720881261, Test Loss: 0.7619863344090325, Inverse Test Loss: 4.265250887189593 
2025-01-10 14:57:37,652 INFO: Epoch 30, Train Loss: 0.7816195028637527, Test Loss: 0.7571780788046973, Inverse Test Loss: 4.207172393798828 
2025-01-10 14:57:38,867 INFO: Epoch 31, Train Loss: 0.7809622276813613, Test Loss: 0.7559182580028262, Inverse Test Loss: 4.24517468043736 
2025-01-10 14:57:40,169 INFO: Epoch 32, Train Loss: 0.7813065199677004, Test Loss: 0.7579277328082493, Inverse Test Loss: 4.289785385131836 
2025-01-10 14:57:41,377 INFO: Epoch 33, Train Loss: 0.7800089066181708, Test Loss: 0.756084252681051, Inverse Test Loss: 4.396723066057477 
2025-01-10 14:57:42,929 INFO: Epoch 34, Train Loss: 0.7794717222178748, Test Loss: 0.7566537793193545, Inverse Test Loss: 4.211127962384905 
2025-01-10 14:57:44,552 INFO: Epoch 35, Train Loss: 0.780470517250376, Test Loss: 0.7525798401662281, Inverse Test Loss: 4.238207135881696 
2025-01-10 14:57:46,090 INFO: Epoch 36, Train Loss: 0.7789415782744732, Test Loss: 0.7543093242815563, Inverse Test Loss: 4.39783069065639 
2025-01-10 14:57:47,597 INFO: Epoch 37, Train Loss: 0.7783908275289273, Test Loss: 0.7523439909730639, Inverse Test Loss: 4.267146519252232 
2025-01-10 14:57:49,117 INFO: Epoch 38, Train Loss: 0.7788549339005707, Test Loss: 0.753715021269662, Inverse Test Loss: 4.360374178205218 
2025-01-10 14:57:50,647 INFO: Epoch 39, Train Loss: 0.776991481627893, Test Loss: 0.7500989309379033, Inverse Test Loss: 4.189122336251395 
2025-01-10 14:57:52,202 INFO: Epoch 40, Train Loss: 0.7747448584355345, Test Loss: 0.749038136431149, Inverse Test Loss: 4.165568760463169 
2025-01-10 14:57:53,718 INFO: Epoch 41, Train Loss: 0.776760969140114, Test Loss: 0.7491572222539357, Inverse Test Loss: 4.12410272870745 
2025-01-10 14:57:55,166 INFO: Epoch 42, Train Loss: 0.7747021219052306, Test Loss: 0.7487711012363434, Inverse Test Loss: 4.13918331691197 
2025-01-10 14:57:56,812 INFO: Epoch 43, Train Loss: 0.77196128269948, Test Loss: 0.7481130680867604, Inverse Test Loss: 4.263406481061663 
2025-01-10 14:57:58,429 INFO: Epoch 44, Train Loss: 0.7725293958952667, Test Loss: 0.7458339184522629, Inverse Test Loss: 4.049333844866071 
2025-01-10 14:58:00,017 INFO: Epoch 45, Train Loss: 0.7724363065640861, Test Loss: 0.7452501973935536, Inverse Test Loss: 4.091193880353655 
2025-01-10 14:58:01,746 INFO: Epoch 46, Train Loss: 0.7735327356452242, Test Loss: 0.746543533035687, Inverse Test Loss: 4.175385611397879 
2025-01-10 14:58:03,161 INFO: Epoch 47, Train Loss: 0.7719667078158178, Test Loss: 0.7492486259766987, Inverse Test Loss: 4.461961201259068 
2025-01-10 14:58:04,516 INFO: Epoch 48, Train Loss: 0.7744904783887601, Test Loss: 0.7457263086523328, Inverse Test Loss: 4.042670658656529 
2025-01-10 14:58:05,825 INFO: Epoch 49, Train Loss: 0.7736749479530054, Test Loss: 0.7443273386784962, Inverse Test Loss: 4.2040813991001675 
2025-01-10 14:58:07,275 INFO: Epoch 50, Train Loss: 0.7703327804530432, Test Loss: 0.7416632111583438, Inverse Test Loss: 4.086421421595982 
2025-01-10 14:58:08,980 INFO: Epoch 51, Train Loss: 0.7681853175163269, Test Loss: 0.7411238529852459, Inverse Test Loss: 3.95891843523298 
2025-01-10 14:58:10,619 INFO: Epoch 52, Train Loss: 0.768463581527045, Test Loss: 0.7423788756132126, Inverse Test Loss: 3.929798126220703 
2025-01-10 14:58:12,091 INFO: Epoch 53, Train Loss: 0.7686238113893281, Test Loss: 0.7452577203512192, Inverse Test Loss: 4.34204237801688 
2025-01-10 14:58:13,599 INFO: Epoch 54, Train Loss: 0.7687318456282309, Test Loss: 0.7422688560826438, Inverse Test Loss: 4.051293509347098 
2025-01-10 14:58:15,291 INFO: Epoch 55, Train Loss: 0.7694267526679083, Test Loss: 0.740558996796608, Inverse Test Loss: 4.122704914637974 
