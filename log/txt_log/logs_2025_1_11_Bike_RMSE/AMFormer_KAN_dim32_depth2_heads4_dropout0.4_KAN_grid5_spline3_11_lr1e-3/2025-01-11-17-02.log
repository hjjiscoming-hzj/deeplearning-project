2025-01-11 17:02:23,385 INFO: namespace(attn_dropout=0.4, categories=[], cluster=3, depth=2, dim=32, ff_dropout=0.4, groups=[54, 54, 54], heads=4, name='AMFormer_KAN_dim32_depth2_heads4_dropout0.4_KAN_grid5_spline3', num_cate=0, num_cont=53, num_special_tokens=1, out=1, out_dim=1, predictor='KAN', prod_num_per_group=[6, 6, 6], qk_relu=False, sum_num_per_group=[32, 16, 8], target_mode='regression', token_descent=False, use_cls_token=True, use_prod=True, use_sigmoid=True) 
2025-01-11 17:02:23,385 INFO: Dataset:Bike 
2025-01-11 17:02:23,385 INFO: ------Begin Training Model------ 
2025-01-11 17:02:30,133 INFO: Epoch 1, Train Loss: 0.8696007739513292, Test Loss: 0.6257517955132893, Inverse Test Loss: 3.55572509765625 
2025-01-11 17:02:32,407 INFO: Epoch 2, Train Loss: 0.5995792853176047, Test Loss: 0.5002150886825153, Inverse Test Loss: 4.378310067313058 
2025-01-11 17:02:34,556 INFO: Epoch 3, Train Loss: 0.5387600138099915, Test Loss: 0.4618311013494219, Inverse Test Loss: 3.9129257202148438 
2025-01-11 17:02:36,901 INFO: Epoch 4, Train Loss: 0.485128130934654, Test Loss: 0.38785599917173386, Inverse Test Loss: 3.183609281267439 
2025-01-11 17:02:39,211 INFO: Epoch 5, Train Loss: 0.4141929961672617, Test Loss: 0.33599032142332624, Inverse Test Loss: 1.9573623112269811 
2025-01-11 17:02:41,522 INFO: Epoch 6, Train Loss: 0.3701669169128488, Test Loss: 0.3226959742605686, Inverse Test Loss: 2.0187249864850725 
2025-01-11 17:02:43,968 INFO: Epoch 7, Train Loss: 0.33744115867745983, Test Loss: 0.28250199503132273, Inverse Test Loss: 1.6570910045078822 
2025-01-11 17:02:46,302 INFO: Epoch 8, Train Loss: 0.3264365953589798, Test Loss: 0.29061898429478916, Inverse Test Loss: 1.4142532348632812 
2025-01-11 17:02:48,792 INFO: Epoch 9, Train Loss: 0.3145189542289174, Test Loss: 0.28976000579340117, Inverse Test Loss: 1.4361156736101424 
2025-01-11 17:02:51,379 INFO: Epoch 10, Train Loss: 0.30522731671092707, Test Loss: 0.2578702537076814, Inverse Test Loss: 1.1324417250497 
2025-01-11 17:02:53,809 INFO: Epoch 11, Train Loss: 0.29139474909239954, Test Loss: 0.2520915163414819, Inverse Test Loss: 1.386324201311384 
2025-01-11 17:02:56,414 INFO: Epoch 12, Train Loss: 0.2837284975642458, Test Loss: 0.2872141993471554, Inverse Test Loss: 1.7352838516235352 
2025-01-11 17:02:58,782 INFO: Epoch 13, Train Loss: 0.2796066511388219, Test Loss: 0.25877054940376965, Inverse Test Loss: 1.582517078944615 
2025-01-11 17:03:01,168 INFO: Epoch 14, Train Loss: 0.26976633550377066, Test Loss: 0.26575404352375437, Inverse Test Loss: 1.7954202379499162 
2025-01-11 17:03:03,710 INFO: Epoch 15, Train Loss: 0.2663116576748157, Test Loss: 0.2537138946354389, Inverse Test Loss: 1.570106370108468 
2025-01-11 17:03:06,132 INFO: Epoch 16, Train Loss: 0.2619027116703331, Test Loss: 0.27848207524844576, Inverse Test Loss: 1.8428490502493722 
2025-01-11 17:03:08,592 INFO: Epoch 17, Train Loss: 0.2630053746317505, Test Loss: 0.26735944194453104, Inverse Test Loss: 1.5293456486293249 
2025-01-11 17:03:11,120 INFO: Epoch 18, Train Loss: 0.25638358390659366, Test Loss: 0.2827913255563804, Inverse Test Loss: 1.769496236528669 
2025-01-11 17:03:13,347 INFO: Epoch 19, Train Loss: 0.24839910317998415, Test Loss: 0.2655263692140579, Inverse Test Loss: 1.886355263846261 
2025-01-11 17:03:15,714 INFO: Epoch 20, Train Loss: 0.24760186398794892, Test Loss: 0.24165191235286848, Inverse Test Loss: 1.4580353328159876 
2025-01-11 17:03:18,164 INFO: Epoch 21, Train Loss: 0.24512986415023102, Test Loss: 0.2385156149310725, Inverse Test Loss: 1.601539475577218 
2025-01-11 17:03:20,274 INFO: Epoch 22, Train Loss: 0.2458149197451565, Test Loss: 0.25139674225023817, Inverse Test Loss: 1.84958130972726 
2025-01-11 17:03:22,401 INFO: Epoch 23, Train Loss: 0.24155317506658922, Test Loss: 0.23746192614947045, Inverse Test Loss: 1.58796569279262 
2025-01-11 17:03:24,845 INFO: Epoch 24, Train Loss: 0.2376841232864135, Test Loss: 0.24026609744344438, Inverse Test Loss: 1.6309093747820174 
2025-01-11 17:03:27,111 INFO: Epoch 25, Train Loss: 0.23674317497179048, Test Loss: 0.23072960121291025, Inverse Test Loss: 1.3766213825770788 
2025-01-11 17:03:29,671 INFO: Epoch 26, Train Loss: 0.23356946414216942, Test Loss: 0.24707431133304322, Inverse Test Loss: 1.7187806538173132 
2025-01-11 17:03:31,912 INFO: Epoch 27, Train Loss: 0.23411698297623101, Test Loss: 0.2358118418071951, Inverse Test Loss: 1.9224649156842912 
2025-01-11 17:03:34,092 INFO: Epoch 28, Train Loss: 0.2293921099343431, Test Loss: 0.24490861488240107, Inverse Test Loss: 1.656007902962821 
2025-01-11 17:03:36,307 INFO: Epoch 29, Train Loss: 0.23128596522392483, Test Loss: 0.23217131037797248, Inverse Test Loss: 1.4104712350027901 
2025-01-11 17:03:38,908 INFO: Epoch 30, Train Loss: 0.22638976710651992, Test Loss: 0.2398491773222174, Inverse Test Loss: 1.6739497865949358 
2025-01-11 17:03:41,293 INFO: Epoch 31, Train Loss: 0.2282447935244359, Test Loss: 0.22959328070282936, Inverse Test Loss: 1.3840571812220983 
2025-01-11 17:03:43,562 INFO: Epoch 32, Train Loss: 0.2241613601052433, Test Loss: 0.2340194471180439, Inverse Test Loss: 1.6003235408238001 
2025-01-11 17:03:45,829 INFO: Epoch 33, Train Loss: 0.22043607841937915, Test Loss: 0.23432975368840353, Inverse Test Loss: 1.6814414433070592 
2025-01-11 17:03:48,004 INFO: Epoch 34, Train Loss: 0.2206941205974019, Test Loss: 0.24174479767680168, Inverse Test Loss: 1.6496892656598772 
2025-01-11 17:03:50,474 INFO: Epoch 35, Train Loss: 0.21849281251977343, Test Loss: 0.2328361560191427, Inverse Test Loss: 1.4886629922049386 
2025-01-11 17:03:52,758 INFO: Epoch 36, Train Loss: 0.2182612752695696, Test Loss: 0.22965463676622935, Inverse Test Loss: 1.591850689479283 
2025-01-11 17:03:55,130 INFO: Epoch 37, Train Loss: 0.21860703743925883, Test Loss: 0.24619305453130177, Inverse Test Loss: 1.733788354056222 
2025-01-11 17:03:57,568 INFO: Epoch 38, Train Loss: 0.2146259167599022, Test Loss: 0.23126751876303128, Inverse Test Loss: 1.5700669969831194 
2025-01-11 17:03:59,908 INFO: Epoch 39, Train Loss: 0.21519783604035683, Test Loss: 0.2301772886088916, Inverse Test Loss: 1.6184026173182897 
2025-01-11 17:04:02,083 INFO: Epoch 40, Train Loss: 0.21261732567340955, Test Loss: 0.22199852179203713, Inverse Test Loss: 1.4256906509399414 
2025-01-11 17:04:04,358 INFO: Epoch 41, Train Loss: 0.21119785965035814, Test Loss: 0.2242919323699815, Inverse Test Loss: 1.5282001495361328 
2025-01-11 17:04:06,823 INFO: Epoch 42, Train Loss: 0.20984737506700218, Test Loss: 0.22472166270017624, Inverse Test Loss: 1.6387473515101842 
2025-01-11 17:04:09,178 INFO: Epoch 43, Train Loss: 0.2142537859601712, Test Loss: 0.23650370857545308, Inverse Test Loss: 1.746305056980678 
2025-01-11 17:04:11,598 INFO: Epoch 44, Train Loss: 0.20543792461036542, Test Loss: 0.2392379210463592, Inverse Test Loss: 1.7829591206141882 
2025-01-11 17:04:14,096 INFO: Epoch 45, Train Loss: 0.20723608929082887, Test Loss: 0.239806916564703, Inverse Test Loss: 1.7261104583740234 
2025-01-11 17:04:16,443 INFO: Epoch 46, Train Loss: 0.2046370168618106, Test Loss: 0.2262902951666287, Inverse Test Loss: 1.512976782662528 
2025-01-11 17:04:18,781 INFO: Epoch 47, Train Loss: 0.20785934266147263, Test Loss: 0.23246526877794946, Inverse Test Loss: 1.6675119400024414 
2025-01-11 17:04:20,917 INFO: Epoch 48, Train Loss: 0.20065346633622405, Test Loss: 0.2259683683514595, Inverse Test Loss: 1.4906116213117326 
2025-01-11 17:04:23,148 INFO: Epoch 49, Train Loss: 0.20315695219083663, Test Loss: 0.22658647916146687, Inverse Test Loss: 1.4783338819231306 
2025-01-11 17:04:25,507 INFO: Epoch 50, Train Loss: 0.20135330757416717, Test Loss: 0.2309012391737529, Inverse Test Loss: 1.4927000318254744 
2025-01-11 17:04:27,659 INFO: Epoch 51, Train Loss: 0.20346345171469069, Test Loss: 0.24245246074029378, Inverse Test Loss: 1.7518397739955358 
2025-01-11 17:04:29,800 INFO: Epoch 52, Train Loss: 0.19942405983942366, Test Loss: 0.22778822534850665, Inverse Test Loss: 1.5681818553379603 
2025-01-11 17:04:31,928 INFO: Epoch 53, Train Loss: 0.19565311197294008, Test Loss: 0.22803855261632375, Inverse Test Loss: 1.6243945530482702 
2025-01-11 17:04:34,099 INFO: Epoch 54, Train Loss: 0.19755849009806956, Test Loss: 0.22779120451637677, Inverse Test Loss: 1.545682089669364 
2025-01-11 17:04:36,219 INFO: Epoch 55, Train Loss: 0.19795390977225172, Test Loss: 0.22780553145068033, Inverse Test Loss: 1.4150396074567522 
2025-01-11 17:04:38,381 INFO: Epoch 56, Train Loss: 0.1955716432234563, Test Loss: 0.2269273708973612, Inverse Test Loss: 1.5948216574532645 
2025-01-11 17:04:40,589 INFO: Epoch 57, Train Loss: 0.19372967336702784, Test Loss: 0.22745446541479655, Inverse Test Loss: 1.523465701511928 
2025-01-11 17:04:42,728 INFO: Epoch 58, Train Loss: 0.19176165103365522, Test Loss: 0.2340143998818738, Inverse Test Loss: 1.6971819741385323 
2025-01-11 17:04:44,903 INFO: Epoch 59, Train Loss: 0.18870658215579636, Test Loss: 0.22527481988072395, Inverse Test Loss: 1.5268639155796595 
2025-01-11 17:04:47,106 INFO: Epoch 60, Train Loss: 0.19076749039899318, Test Loss: 0.22613186602081572, Inverse Test Loss: 1.4229957035609655 
2025-01-11 17:04:49,311 INFO: Epoch 61, Train Loss: 0.18891454863985743, Test Loss: 0.2236676003251757, Inverse Test Loss: 1.588987214224679 
2025-01-11 17:04:51,545 INFO: Epoch 62, Train Loss: 0.18766204739382508, Test Loss: 0.22875706478953362, Inverse Test Loss: 1.6519298553466797 
2025-01-11 17:04:53,810 INFO: Epoch 63, Train Loss: 0.1884517787246529, Test Loss: 0.22230319678783417, Inverse Test Loss: 1.5466854912894112 
2025-01-11 17:04:56,039 INFO: Epoch 64, Train Loss: 0.1854887753725052, Test Loss: 0.22584945974605425, Inverse Test Loss: 1.4143492834908622 
2025-01-11 17:04:58,217 INFO: Epoch 65, Train Loss: 0.1877562567728375, Test Loss: 0.2243605421057769, Inverse Test Loss: 1.541006224496024 
2025-01-11 17:05:00,517 INFO: Epoch 66, Train Loss: 0.18604834022325115, Test Loss: 0.22839680739811488, Inverse Test Loss: 1.5642806461879186 
2025-01-11 17:05:02,844 INFO: Epoch 67, Train Loss: 0.18580173748895662, Test Loss: 0.2229390170957361, Inverse Test Loss: 1.6121345247541154 
2025-01-11 17:05:04,949 INFO: Epoch 68, Train Loss: 0.1866711641943783, Test Loss: 0.22582284840089933, Inverse Test Loss: 1.5566893986293249 
2025-01-11 17:05:07,039 INFO: Epoch 69, Train Loss: 0.18348155847383202, Test Loss: 0.22202764132193156, Inverse Test Loss: 1.4539775848388672 
2025-01-11 17:05:09,149 INFO: Epoch 70, Train Loss: 0.18209356233614302, Test Loss: 0.22263546288013458, Inverse Test Loss: 1.5624137605939592 
2025-01-11 17:05:11,359 INFO: Epoch 71, Train Loss: 0.18036655322947634, Test Loss: 0.23449034722787993, Inverse Test Loss: 1.7311756951468331 
2025-01-11 17:05:13,515 INFO: Epoch 72, Train Loss: 0.1824391153427439, Test Loss: 0.22760840132832527, Inverse Test Loss: 1.5938163484845842 
2025-01-11 17:05:15,680 INFO: Epoch 73, Train Loss: 0.17985459041157995, Test Loss: 0.22255598327943257, Inverse Test Loss: 1.5770893096923828 
2025-01-11 17:05:17,826 INFO: Epoch 74, Train Loss: 0.182053909184189, Test Loss: 0.22224501999361174, Inverse Test Loss: 1.5558947154453822 
2025-01-11 17:05:20,000 INFO: Epoch 75, Train Loss: 0.1799615314657535, Test Loss: 0.22801068212304795, Inverse Test Loss: 1.7121230534144811 
2025-01-11 17:05:22,161 INFO: Epoch 76, Train Loss: 0.1788604768044358, Test Loss: 0.22596304597599165, Inverse Test Loss: 1.5259160995483398 
2025-01-11 17:05:24,287 INFO: Epoch 77, Train Loss: 0.1780533962840334, Test Loss: 0.2263891627745969, Inverse Test Loss: 1.510070528302874 
2025-01-11 17:05:26,500 INFO: Epoch 78, Train Loss: 0.1772384741984376, Test Loss: 0.2266755040202822, Inverse Test Loss: 1.5147281374250139 
2025-01-11 17:05:28,711 INFO: Epoch 79, Train Loss: 0.17551404183064032, Test Loss: 0.23494910768100194, Inverse Test Loss: 1.5572690963745117 
2025-01-11 17:05:30,980 INFO: Epoch 80, Train Loss: 0.18226076074696462, Test Loss: 0.2283510666872774, Inverse Test Loss: 1.5348190580095564 
2025-01-11 17:05:33,220 INFO: Epoch 81, Train Loss: 0.17739263422992252, Test Loss: 0.22871492430567741, Inverse Test Loss: 1.5777324948992049 
2025-01-11 17:05:35,339 INFO: Epoch 82, Train Loss: 0.17484235230388992, Test Loss: 0.22414736609373773, Inverse Test Loss: 1.582225935799735 
2025-01-11 17:05:37,434 INFO: Epoch 83, Train Loss: 0.17347173009990552, Test Loss: 0.2294754758477211, Inverse Test Loss: 1.6975024087088448 
2025-01-11 17:05:39,545 INFO: Epoch 84, Train Loss: 0.17377727512919575, Test Loss: 0.23000575655273028, Inverse Test Loss: 1.633049419948033 
2025-01-11 17:05:41,705 INFO: Epoch 85, Train Loss: 0.1732347156476537, Test Loss: 0.2271515503525734, Inverse Test Loss: 1.5887201854160853 
2025-01-11 17:05:43,818 INFO: Epoch 86, Train Loss: 0.17420753064232136, Test Loss: 0.22708123443382128, Inverse Test Loss: 1.5109812872750419 
2025-01-11 17:05:45,890 INFO: Epoch 87, Train Loss: 0.1721328297339448, Test Loss: 0.22813189827970096, Inverse Test Loss: 1.4883277075631278 
2025-01-11 17:05:47,970 INFO: Epoch 88, Train Loss: 0.16780913122203373, Test Loss: 0.23167609689491137, Inverse Test Loss: 1.538754871913365 
2025-01-11 17:05:50,082 INFO: Epoch 89, Train Loss: 0.16917330792190832, Test Loss: 0.22574774122663907, Inverse Test Loss: 1.5754552568708147 
2025-01-11 17:05:52,193 INFO: Epoch 90, Train Loss: 0.16947833838265972, Test Loss: 0.22612773520605906, Inverse Test Loss: 1.6645818437848772 
2025-01-11 17:05:54,332 INFO: Epoch 91, Train Loss: 0.16873315523523802, Test Loss: 0.2238475297178541, Inverse Test Loss: 1.5673341751098633 
2025-01-11 17:05:56,480 INFO: Epoch 92, Train Loss: 0.16616134345531464, Test Loss: 0.22501835067357337, Inverse Test Loss: 1.6217365264892578 
2025-01-11 17:05:58,598 INFO: Epoch 93, Train Loss: 0.1652144327623035, Test Loss: 0.22485599932926043, Inverse Test Loss: 1.4283959524972099 
2025-01-11 17:06:00,714 INFO: Epoch 94, Train Loss: 0.1691061824970289, Test Loss: 0.2257378569671086, Inverse Test Loss: 1.4096272332327706 
2025-01-11 17:06:02,840 INFO: Epoch 95, Train Loss: 0.166978302830403, Test Loss: 0.23075859727604048, Inverse Test Loss: 1.4779153551374162 
2025-01-11 17:06:05,025 INFO: Epoch 96, Train Loss: 0.16706753323931212, Test Loss: 0.21981006381767138, Inverse Test Loss: 1.5609931945800781 
2025-01-11 17:06:07,205 INFO: Epoch 97, Train Loss: 0.1659720854474864, Test Loss: 0.22417036071419716, Inverse Test Loss: 1.480166026524135 
2025-01-11 17:06:09,403 INFO: Epoch 98, Train Loss: 0.16567144125973413, Test Loss: 0.2261901173208441, Inverse Test Loss: 1.3974302836826868 
2025-01-11 17:06:11,570 INFO: Epoch 99, Train Loss: 0.16551637341943357, Test Loss: 0.23142134823969432, Inverse Test Loss: 1.5277098246983118 
2025-01-11 17:06:13,741 INFO: Epoch 100, Train Loss: 0.16237073036235408, Test Loss: 0.2278010222528662, Inverse Test Loss: 1.5561189651489258 
2025-01-11 17:06:13,741 INFO: Best Epoch 96, Best Test Loss: 0.21981006381767138 
2025-01-11 17:06:15,851 INFO: Epoch 101, Train Loss: 0.16498198127801264, Test Loss: 0.2279835950051035, Inverse Test Loss: 1.7008959906441825 
2025-01-11 17:06:17,931 INFO: Epoch 102, Train Loss: 0.1637500822544098, Test Loss: 0.22981025651097298, Inverse Test Loss: 1.7299770627702986 
2025-01-11 17:06:20,054 INFO: Epoch 103, Train Loss: 0.1620574832782833, Test Loss: 0.23006639363510267, Inverse Test Loss: 1.6707049778529577 
2025-01-11 17:06:22,091 INFO: Epoch 104, Train Loss: 0.1656899002440479, Test Loss: 0.2263419617499624, Inverse Test Loss: 1.7316587993076868 
2025-01-11 17:06:24,366 INFO: Epoch 105, Train Loss: 0.16132267243271575, Test Loss: 0.22771794189299857, Inverse Test Loss: 1.6073834555489677 
2025-01-11 17:06:26,651 INFO: Epoch 106, Train Loss: 0.1618901160332041, Test Loss: 0.22714970473732268, Inverse Test Loss: 1.5988517488752092 
2025-01-11 17:06:28,826 INFO: Epoch 107, Train Loss: 0.15988663399438247, Test Loss: 0.22788633459380694, Inverse Test Loss: 1.6416729518345423 
2025-01-11 17:06:31,016 INFO: Epoch 108, Train Loss: 0.1575907419580932, Test Loss: 0.22718806405152595, Inverse Test Loss: 1.555227279663086 
2025-01-11 17:06:33,331 INFO: Epoch 109, Train Loss: 0.1590158560680687, Test Loss: 0.22996853877391135, Inverse Test Loss: 1.757486343383789 
2025-01-11 17:06:35,596 INFO: Epoch 110, Train Loss: 0.1630878975495286, Test Loss: 0.22972748641456878, Inverse Test Loss: 1.5753468104771204 
