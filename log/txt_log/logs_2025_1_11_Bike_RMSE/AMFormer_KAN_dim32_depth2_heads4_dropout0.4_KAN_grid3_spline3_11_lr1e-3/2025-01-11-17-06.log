2025-01-11 17:06:55,951 INFO: namespace(attn_dropout=0.4, categories=[], cluster=3, depth=2, dim=32, ff_dropout=0.4, groups=[54, 54, 54], heads=4, name='AMFormer_KAN_dim32_depth2_heads4_dropout0.4_KAN_grid3_spline3', num_cate=0, num_cont=53, num_special_tokens=1, out=1, out_dim=1, predictor='KAN', prod_num_per_group=[6, 6, 6], qk_relu=False, sum_num_per_group=[32, 16, 8], target_mode='regression', token_descent=False, use_cls_token=True, use_prod=True, use_sigmoid=True) 
2025-01-11 17:06:55,951 INFO: Dataset:Bike 
2025-01-11 17:06:55,951 INFO: ------Begin Training Model------ 
2025-01-11 17:07:02,596 INFO: Epoch 1, Train Loss: 0.8846539237083645, Test Loss: 0.6329872267586845, Inverse Test Loss: 4.512607574462891 
2025-01-11 17:07:04,787 INFO: Epoch 2, Train Loss: 0.6029436711324464, Test Loss: 0.515608335179942, Inverse Test Loss: 4.386250359671457 
2025-01-11 17:07:06,935 INFO: Epoch 3, Train Loss: 0.5491909472220534, Test Loss: 0.4806201894368444, Inverse Test Loss: 4.333874021257673 
2025-01-11 17:07:09,148 INFO: Epoch 4, Train Loss: 0.47580094512449495, Test Loss: 0.37136170480932507, Inverse Test Loss: 3.2715039934430803 
2025-01-11 17:07:11,626 INFO: Epoch 5, Train Loss: 0.40528924612823974, Test Loss: 0.32662090978452135, Inverse Test Loss: 2.4310692378452847 
2025-01-11 17:07:14,259 INFO: Epoch 6, Train Loss: 0.3778080746121363, Test Loss: 0.31335728242993355, Inverse Test Loss: 2.2838735580444336 
2025-01-11 17:07:16,456 INFO: Epoch 7, Train Loss: 0.35665789465291786, Test Loss: 0.31937555010829655, Inverse Test Loss: 1.991636140005929 
2025-01-11 17:07:18,903 INFO: Epoch 8, Train Loss: 0.3427675158605663, Test Loss: 0.3010966697973864, Inverse Test Loss: 1.711181640625 
2025-01-11 17:07:21,217 INFO: Epoch 9, Train Loss: 0.33127941478283035, Test Loss: 0.29224948585033417, Inverse Test Loss: 1.511544636317662 
2025-01-11 17:07:23,726 INFO: Epoch 10, Train Loss: 0.31741181426092024, Test Loss: 0.27461810037493706, Inverse Test Loss: 1.5374785831996374 
2025-01-11 17:07:26,145 INFO: Epoch 11, Train Loss: 0.30774439789286445, Test Loss: 0.2943564350051539, Inverse Test Loss: 2.101970672607422 
2025-01-11 17:07:28,726 INFO: Epoch 12, Train Loss: 0.29788748919963837, Test Loss: 0.28897646921021597, Inverse Test Loss: 1.9565342494419642 
2025-01-11 17:07:31,059 INFO: Epoch 13, Train Loss: 0.2973787621894014, Test Loss: 0.26955071251307217, Inverse Test Loss: 1.489236286708287 
2025-01-11 17:07:33,135 INFO: Epoch 14, Train Loss: 0.2893677761248492, Test Loss: 0.25829505760754856, Inverse Test Loss: 1.3169195992606026 
2025-01-11 17:07:35,227 INFO: Epoch 15, Train Loss: 0.2864379035223515, Test Loss: 0.2615118825009891, Inverse Test Loss: 1.7266697202410017 
2025-01-11 17:07:37,343 INFO: Epoch 16, Train Loss: 0.27506417295801533, Test Loss: 0.2574463284441403, Inverse Test Loss: 1.6208241326468331 
2025-01-11 17:07:39,403 INFO: Epoch 17, Train Loss: 0.27345711320912075, Test Loss: 0.24868588788168772, Inverse Test Loss: 1.5925516401018416 
2025-01-11 17:07:41,463 INFO: Epoch 18, Train Loss: 0.2743879577162069, Test Loss: 0.27321927302650045, Inverse Test Loss: 1.8259882245744978 
2025-01-11 17:07:43,536 INFO: Epoch 19, Train Loss: 0.264405430320206, Test Loss: 0.254285741597414, Inverse Test Loss: 1.6922896248953683 
2025-01-11 17:07:45,711 INFO: Epoch 20, Train Loss: 0.2648963303467549, Test Loss: 0.2630956470966339, Inverse Test Loss: 1.9171158926827567 
2025-01-11 17:07:47,962 INFO: Epoch 21, Train Loss: 0.2624257176841071, Test Loss: 0.24270303866692952, Inverse Test Loss: 1.4390946796962194 
2025-01-11 17:07:50,335 INFO: Epoch 22, Train Loss: 0.2599149242453619, Test Loss: 0.238501814859254, Inverse Test Loss: 1.6910903113228934 
2025-01-11 17:07:52,559 INFO: Epoch 23, Train Loss: 0.25450400652688576, Test Loss: 0.24031258108360426, Inverse Test Loss: 1.611461775643485 
2025-01-11 17:07:55,082 INFO: Epoch 24, Train Loss: 0.2480036423567238, Test Loss: 0.2405987051980836, Inverse Test Loss: 1.5376537867954798 
2025-01-11 17:07:57,491 INFO: Epoch 25, Train Loss: 0.2461445250915825, Test Loss: 0.23830792999693326, Inverse Test Loss: 1.5851857321602958 
