2025-01-11 17:00:27,054 INFO: namespace(attn_dropout=0.4, categories=[], cluster=3, depth=2, dim=32, ff_dropout=0.4, groups=[54, 54, 54], heads=4, name='AMFormer_simple_MLP_dim32_depth2_heads4_dropout0.4_simple_MLP', num_cate=0, num_cont=53, num_special_tokens=1, out=1, out_dim=1, predictor='simple_MLP', prod_num_per_group=[6, 6, 6], qk_relu=False, sum_num_per_group=[32, 16, 8], target_mode='regression', token_descent=False, use_cls_token=True, use_prod=True, use_sigmoid=True) 
2025-01-11 17:00:27,054 INFO: Dataset:Bike 
2025-01-11 17:00:27,054 INFO: ------Begin Training Model------ 
2025-01-11 17:00:33,238 INFO: Epoch 1, Train Loss: 0.8490982400167972, Test Loss: 0.5781638068812234, Inverse Test Loss: 4.337614331926618 
2025-01-11 17:00:35,121 INFO: Epoch 2, Train Loss: 0.5953686374043106, Test Loss: 0.5088316830141204, Inverse Test Loss: 3.895137514386858 
2025-01-11 17:00:37,047 INFO: Epoch 3, Train Loss: 0.5433752052827713, Test Loss: 0.48638970085552763, Inverse Test Loss: 4.2844856807163785 
2025-01-11 17:00:39,046 INFO: Epoch 4, Train Loss: 0.4897546989655276, Test Loss: 0.42639388889074326, Inverse Test Loss: 4.034657887050083 
2025-01-11 17:00:40,866 INFO: Epoch 5, Train Loss: 0.42787008958125333, Test Loss: 0.35624833192144123, Inverse Test Loss: 2.8025335584368025 
2025-01-11 17:00:42,672 INFO: Epoch 6, Train Loss: 0.3897764518720294, Test Loss: 0.33210991642304827, Inverse Test Loss: 2.136338915143694 
2025-01-11 17:00:44,464 INFO: Epoch 7, Train Loss: 0.35505022833106714, Test Loss: 0.32484199319567, Inverse Test Loss: 2.3364691053118025 
2025-01-11 17:00:46,255 INFO: Epoch 8, Train Loss: 0.33917121165389313, Test Loss: 0.30201089116079466, Inverse Test Loss: 1.4179070336478097 
2025-01-11 17:00:48,051 INFO: Epoch 9, Train Loss: 0.33017824275777974, Test Loss: 0.2742694222501346, Inverse Test Loss: 1.299149785723005 
2025-01-11 17:00:49,814 INFO: Epoch 10, Train Loss: 0.3226480135403642, Test Loss: 0.2716265618801117, Inverse Test Loss: 1.4114059720720564 
2025-01-11 17:00:51,598 INFO: Epoch 11, Train Loss: 0.3111296069184574, Test Loss: 0.2750873938202858, Inverse Test Loss: 1.5417569024222237 
2025-01-11 17:00:53,448 INFO: Epoch 12, Train Loss: 0.30140875799393435, Test Loss: 0.2624473385512829, Inverse Test Loss: 1.4147530964442663 
2025-01-11 17:00:55,301 INFO: Epoch 13, Train Loss: 0.29414638589828385, Test Loss: 0.2636250763067177, Inverse Test Loss: 1.187814167567662 
2025-01-11 17:00:57,132 INFO: Epoch 14, Train Loss: 0.2890998990437306, Test Loss: 0.25532122648188044, Inverse Test Loss: 1.3569722856794084 
2025-01-11 17:00:59,004 INFO: Epoch 15, Train Loss: 0.2817440757510859, Test Loss: 0.2521145726953234, Inverse Test Loss: 1.2655794961111886 
2025-01-11 17:01:00,873 INFO: Epoch 16, Train Loss: 0.2820850757010486, Test Loss: 0.24469565280846187, Inverse Test Loss: 1.2276637213570731 
2025-01-11 17:01:02,712 INFO: Epoch 17, Train Loss: 0.2741319419593986, Test Loss: 0.24215965505157197, Inverse Test Loss: 1.4019971575055803 
2025-01-11 17:01:04,502 INFO: Epoch 18, Train Loss: 0.2676759005413143, Test Loss: 0.24653360673359462, Inverse Test Loss: 1.2600747517177038 
2025-01-11 17:01:06,355 INFO: Epoch 19, Train Loss: 0.26534728200063795, Test Loss: 0.2424810039145606, Inverse Test Loss: 1.1292201450892858 
2025-01-11 17:01:08,252 INFO: Epoch 20, Train Loss: 0.26556519712876836, Test Loss: 0.24201155666794097, Inverse Test Loss: 1.2664969308035714 
2025-01-11 17:01:10,096 INFO: Epoch 21, Train Loss: 0.2600144640021368, Test Loss: 0.24763893921460425, Inverse Test Loss: 1.2307515825544084 
2025-01-11 17:01:11,874 INFO: Epoch 22, Train Loss: 0.26053248304839527, Test Loss: 0.24413870008928434, Inverse Test Loss: 1.3478501183646066 
2025-01-11 17:01:13,738 INFO: Epoch 23, Train Loss: 0.2584709272198721, Test Loss: 0.24241538611905916, Inverse Test Loss: 1.2472178595406669 
2025-01-11 17:01:15,660 INFO: Epoch 24, Train Loss: 0.2550044344105852, Test Loss: 0.23765528734241212, Inverse Test Loss: 1.3222710745675224 
2025-01-11 17:01:17,446 INFO: Epoch 25, Train Loss: 0.2529579976556498, Test Loss: 0.23862243922693388, Inverse Test Loss: 1.2902537754603796 
2025-01-11 17:01:19,329 INFO: Epoch 26, Train Loss: 0.2530115812743476, Test Loss: 0.24824680707284383, Inverse Test Loss: 1.361360686165946 
2025-01-11 17:01:21,109 INFO: Epoch 27, Train Loss: 0.24892324550983008, Test Loss: 0.23343967007739203, Inverse Test Loss: 1.3683911732264928 
2025-01-11 17:01:22,942 INFO: Epoch 28, Train Loss: 0.24484372685808653, Test Loss: 0.23455991542765073, Inverse Test Loss: 1.3652988161359514 
2025-01-11 17:01:24,778 INFO: Epoch 29, Train Loss: 0.24541772300497108, Test Loss: 0.23821197929126875, Inverse Test Loss: 1.3334813799176897 
2025-01-11 17:01:26,561 INFO: Epoch 30, Train Loss: 0.2415712550966018, Test Loss: 0.22335215019328253, Inverse Test Loss: 1.1149465697152274 
2025-01-11 17:01:28,320 INFO: Epoch 31, Train Loss: 0.23818014329726542, Test Loss: 0.2290736325085163, Inverse Test Loss: 1.4266249792916434 
2025-01-11 17:01:30,105 INFO: Epoch 32, Train Loss: 0.2386436831513676, Test Loss: 0.2369248808494636, Inverse Test Loss: 1.332130295889718 
2025-01-11 17:01:31,889 INFO: Epoch 33, Train Loss: 0.23674875839587745, Test Loss: 0.23121256647365435, Inverse Test Loss: 1.2471836635044642 
2025-01-11 17:01:33,691 INFO: Epoch 34, Train Loss: 0.23379691820079035, Test Loss: 0.23300587545548165, Inverse Test Loss: 1.3504359381539481 
2025-01-11 17:01:35,506 INFO: Epoch 35, Train Loss: 0.2347933045767863, Test Loss: 0.23274608488593782, Inverse Test Loss: 1.2963248661586217 
2025-01-11 17:01:37,352 INFO: Epoch 36, Train Loss: 0.2325976918870156, Test Loss: 0.22685001843741961, Inverse Test Loss: 1.3050428118024553 
2025-01-11 17:01:39,294 INFO: Epoch 37, Train Loss: 0.23241929586874235, Test Loss: 0.22921486145683698, Inverse Test Loss: 1.2823843274797713 
2025-01-11 17:01:41,100 INFO: Epoch 38, Train Loss: 0.22793535368705015, Test Loss: 0.23576036521366664, Inverse Test Loss: 1.5187030519757951 
2025-01-11 17:01:43,042 INFO: Epoch 39, Train Loss: 0.22982611117559834, Test Loss: 0.22637221908995084, Inverse Test Loss: 1.339754513331822 
2025-01-11 17:01:44,845 INFO: Epoch 40, Train Loss: 0.22695933022630324, Test Loss: 0.22941815214497702, Inverse Test Loss: 1.3188306263514928 
2025-01-11 17:01:46,686 INFO: Epoch 41, Train Loss: 0.22829058985097692, Test Loss: 0.22904279881290027, Inverse Test Loss: 1.2993413380214147 
2025-01-11 17:01:48,539 INFO: Epoch 42, Train Loss: 0.2236405907694353, Test Loss: 0.2298955081829003, Inverse Test Loss: 1.3794292722429549 
2025-01-11 17:01:50,323 INFO: Epoch 43, Train Loss: 0.22234877725259974, Test Loss: 0.2242367805114814, Inverse Test Loss: 1.3973568507603236 
2025-01-11 17:01:52,246 INFO: Epoch 44, Train Loss: 0.21878666369193192, Test Loss: 0.22879690197961672, Inverse Test Loss: 1.2728090286254883 
2025-01-11 17:01:54,026 INFO: Epoch 45, Train Loss: 0.21878150775345093, Test Loss: 0.2225328774324485, Inverse Test Loss: 1.2767626898629325 
2025-01-11 17:01:55,885 INFO: Epoch 46, Train Loss: 0.21903214911255267, Test Loss: 0.22257460547345026, Inverse Test Loss: 1.5139455795288086 
2025-01-11 17:01:57,719 INFO: Epoch 47, Train Loss: 0.22129923255618558, Test Loss: 0.23100704752973147, Inverse Test Loss: 1.4073493140084403 
2025-01-11 17:01:59,565 INFO: Epoch 48, Train Loss: 0.21630273923414564, Test Loss: 0.2355238369532994, Inverse Test Loss: 1.439661979675293 
2025-01-11 17:02:01,648 INFO: Epoch 49, Train Loss: 0.21743538196480602, Test Loss: 0.23619682661124639, Inverse Test Loss: 1.5188204901559013 
2025-01-11 17:02:03,524 INFO: Epoch 50, Train Loss: 0.2138448142950688, Test Loss: 0.2222310427044119, Inverse Test Loss: 1.3238577161516463 
2025-01-11 17:02:05,381 INFO: Epoch 51, Train Loss: 0.21628725774791263, Test Loss: 0.22695056082946913, Inverse Test Loss: 1.400834083557129 
2025-01-11 17:02:07,177 INFO: Epoch 52, Train Loss: 0.211778161312462, Test Loss: 0.2282660241637911, Inverse Test Loss: 1.44297913142613 
2025-01-11 17:02:09,040 INFO: Epoch 53, Train Loss: 0.21097532420530232, Test Loss: 0.22351986010159766, Inverse Test Loss: 1.3349689756120955 
2025-01-11 17:02:11,150 INFO: Epoch 54, Train Loss: 0.21077414731913752, Test Loss: 0.2239427055631365, Inverse Test Loss: 1.3191882542201452 
2025-01-11 17:02:13,295 INFO: Epoch 55, Train Loss: 0.2107387695017211, Test Loss: 0.24609732361776487, Inverse Test Loss: 1.6301719120570592 
2025-01-11 17:02:15,328 INFO: Epoch 56, Train Loss: 0.21030645086130964, Test Loss: 0.23270060920289584, Inverse Test Loss: 1.6774444580078125 
2025-01-11 17:02:17,331 INFO: Epoch 57, Train Loss: 0.20888041739070087, Test Loss: 0.23257390250052726, Inverse Test Loss: 1.411909512111119 
