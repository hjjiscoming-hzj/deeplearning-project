2025-01-09 14:52:10,016 INFO: namespace(depth=2, grid_size=5, name='KAN', spline_order=2) 
2025-01-09 14:52:10,016 INFO: Dataset:winequality 
2025-01-09 14:52:10,016 INFO: ------Begin Training Model------ 
2025-01-09 14:52:12,037 INFO: Epoch 1, Train Loss: 0.9478991704602395, Test Loss: 0.9051662012934685, Inverse Test Loss: 0.08286512643098831 
2025-01-09 14:52:12,205 INFO: Epoch 2, Train Loss: 0.9098901748657227, Test Loss: 0.8726649358868599, Inverse Test Loss: 0.08065066486597061 
2025-01-09 14:52:12,342 INFO: Epoch 3, Train Loss: 0.8775257525905487, Test Loss: 0.8472764492034912, Inverse Test Loss: 0.07915128767490387 
2025-01-09 14:52:12,486 INFO: Epoch 4, Train Loss: 0.8491762665010267, Test Loss: 0.8302310779690742, Inverse Test Loss: 0.07822494208812714 
2025-01-09 14:52:12,657 INFO: Epoch 5, Train Loss: 0.8321902540422255, Test Loss: 0.8227916285395622, Inverse Test Loss: 0.07765872031450272 
2025-01-09 14:52:12,799 INFO: Epoch 6, Train Loss: 0.8180011010939076, Test Loss: 0.8188616260886192, Inverse Test Loss: 0.0771976187825203 
2025-01-09 14:52:12,945 INFO: Epoch 7, Train Loss: 0.811118729652897, Test Loss: 0.8143706694245338, Inverse Test Loss: 0.07637448608875275 
2025-01-09 14:52:13,078 INFO: Epoch 8, Train Loss: 0.8047333071308751, Test Loss: 0.8108894377946854, Inverse Test Loss: 0.07591703534126282 
2025-01-09 14:52:13,217 INFO: Epoch 9, Train Loss: 0.7983315067906533, Test Loss: 0.8062806203961372, Inverse Test Loss: 0.07562325149774551 
2025-01-09 14:52:13,349 INFO: Epoch 10, Train Loss: 0.7949531155247842, Test Loss: 0.8043913617730141, Inverse Test Loss: 0.0747479647397995 
2025-01-09 14:52:13,487 INFO: Epoch 11, Train Loss: 0.7885277675044152, Test Loss: 0.8015713915228844, Inverse Test Loss: 0.07402515411376953 
2025-01-09 14:52:13,620 INFO: Epoch 12, Train Loss: 0.7844264122747606, Test Loss: 0.7978712692856789, Inverse Test Loss: 0.07362880557775497 
2025-01-09 14:52:13,752 INFO: Epoch 13, Train Loss: 0.7789051878836847, Test Loss: 0.7950209602713585, Inverse Test Loss: 0.07311274856328964 
2025-01-09 14:52:13,881 INFO: Epoch 14, Train Loss: 0.7738503794516286, Test Loss: 0.7914834171533585, Inverse Test Loss: 0.07257276028394699 
2025-01-09 14:52:14,025 INFO: Epoch 15, Train Loss: 0.767695378872656, Test Loss: 0.7900800034403801, Inverse Test Loss: 0.07242292910814285 
2025-01-09 14:52:14,155 INFO: Epoch 16, Train Loss: 0.7618934108364966, Test Loss: 0.7878146767616272, Inverse Test Loss: 0.07197931408882141 
2025-01-09 14:52:14,289 INFO: Epoch 17, Train Loss: 0.7595929541895466, Test Loss: 0.785189762711525, Inverse Test Loss: 0.0723431333899498 
2025-01-09 14:52:14,420 INFO: Epoch 18, Train Loss: 0.7541952363906368, Test Loss: 0.7828400433063507, Inverse Test Loss: 0.07196176797151566 
2025-01-09 14:52:14,556 INFO: Epoch 19, Train Loss: 0.746869687111147, Test Loss: 0.7823993787169456, Inverse Test Loss: 0.07193875312805176 
2025-01-09 14:52:14,685 INFO: Epoch 20, Train Loss: 0.7439562870610145, Test Loss: 0.7803561836481094, Inverse Test Loss: 0.07150953263044357 
2025-01-09 14:52:14,820 INFO: Epoch 21, Train Loss: 0.7387157620922211, Test Loss: 0.7803806737065315, Inverse Test Loss: 0.07177507877349854 
2025-01-09 14:52:14,952 INFO: Epoch 22, Train Loss: 0.7342244155945317, Test Loss: 0.7789603993296623, Inverse Test Loss: 0.07152193784713745 
2025-01-09 14:52:15,089 INFO: Epoch 23, Train Loss: 0.7295564432297984, Test Loss: 0.777701698243618, Inverse Test Loss: 0.07181907445192337 
2025-01-09 14:52:15,229 INFO: Epoch 24, Train Loss: 0.7212717206247391, Test Loss: 0.7777206003665924, Inverse Test Loss: 0.07176106423139572 
2025-01-09 14:52:15,368 INFO: Epoch 25, Train Loss: 0.7176708002244273, Test Loss: 0.7764819487929344, Inverse Test Loss: 0.07162158191204071 
2025-01-09 14:52:15,510 INFO: Epoch 26, Train Loss: 0.7139102047489535, Test Loss: 0.7757494673132896, Inverse Test Loss: 0.07188763469457626 
2025-01-09 14:52:15,647 INFO: Epoch 27, Train Loss: 0.70781409740448, Test Loss: 0.7761440724134445, Inverse Test Loss: 0.07210427522659302 
